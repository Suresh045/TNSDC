{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Suresh045/TNSDC/blob/main/Feature_Selection_classification_kbest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "\n",
        "# Classification Models\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from xgboost import XGBClassifier\n"
      ],
      "metadata": {
        "id": "w0F6JDluVG-P"
      },
      "id": "w0F6JDluVG-P",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Load dataset\n",
        "dataset = pd.read_csv(\"flightprice.csv\")\n",
        "\n",
        "# Preview dataset\n",
        "print(dataset.head())\n",
        "print(dataset.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nW6l5zi5VH2v",
        "outputId": "08a15832-a54f-4fee-a5b6-9103d5c57281"
      },
      "id": "nW6l5zi5VH2v",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   duration  days_left   airline source_city departure_time  stops  \\\n",
            "0       223          4    IndiGo     Kolkata      Afternoon      0   \n",
            "1       249         29     GoAir       Delhi          Night      0   \n",
            "2       119         17     GoAir       Delhi      Afternoon      0   \n",
            "3       131         26    IndiGo      Mumbai        Evening      0   \n",
            "4        86          3  SpiceJet       Delhi        Evening      0   \n",
            "\n",
            "  arrival_time destination_city     class  price  \n",
            "0    Afternoon        Bangalore   Economy  14087  \n",
            "1      Morning          Kolkata   Economy   6582  \n",
            "2        Night          Kolkata  Business  12654  \n",
            "3      Evening        Hyderabad   Economy   8514  \n",
            "4      Evening          Chennai  Business  11785  \n",
            "Index(['duration', 'days_left', 'airline', 'source_city', 'departure_time',\n",
            "       'stops', 'arrival_time', 'destination_city', 'class', 'price'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Define Independent (X) and Dependent (Y)\n",
        "indep_X = dataset[['duration', 'days_left', 'airline', 'source_city',\n",
        "                   'departure_time', 'stops', 'arrival_time', 'destination_city']]\n",
        "\n",
        "# Target variable (class: Economy / Business)\n",
        "dep_Y = dataset['class']\n"
      ],
      "metadata": {
        "id": "qYMJVnQzVKH9"
      },
      "id": "qYMJVnQzVKH9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Encode target (Economy/Business â†’ 0/1)\n",
        "label_encoder = LabelEncoder()\n",
        "dep_Y_encoded = label_encoder.fit_transform(dep_Y)\n",
        "\n",
        "# One-hot encode categorical features\n",
        "indep_X_encoded = pd.get_dummies(indep_X,\n",
        "                                 columns=['airline', 'source_city', 'departure_time',\n",
        "                                          'arrival_time', 'destination_city'],\n",
        "                                 drop_first=True)\n",
        "\n",
        "print(\"Encoded Feature Columns:\", indep_X_encoded.columns.tolist()[:10], \"...\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djDECuEeVMNY",
        "outputId": "c53d60c2-bedc-4812-d521-8878aaf70ffa"
      },
      "id": "djDECuEeVMNY",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoded Feature Columns: ['duration', 'days_left', 'stops', 'airline_GoAir', 'airline_IndiGo', 'airline_SpiceJet', 'airline_Vistara', 'source_city_Chennai', 'source_city_Delhi', 'source_city_Hyderabad'] ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Feature Selection using SelectKBest (top 5 features)\n",
        "def selectKBest_features(indep_X, dep_Y, k):\n",
        "    selector = SelectKBest(score_func=f_classif, k=k)\n",
        "    fit = selector.fit(indep_X, dep_Y)\n",
        "\n",
        "    selected_mask = selector.get_support()\n",
        "    selected_columns = indep_X.columns[selected_mask]\n",
        "\n",
        "    # Transform dataset to reduced features\n",
        "    X_new = selector.transform(indep_X)\n",
        "\n",
        "    print(\"ðŸŽ¯ Top\", k, \"selected features (SelectKBest):\")\n",
        "    print(selected_columns.tolist())\n",
        "    print(\"\\nFeature Scores:\")\n",
        "    feature_scores = pd.DataFrame({\n",
        "        \"Feature\": indep_X.columns,\n",
        "        \"Score\": fit.scores_\n",
        "    }).sort_values(by=\"Score\", ascending=False)\n",
        "    print(feature_scores.head(k))\n",
        "\n",
        "    return X_new, selected_columns\n",
        "\n",
        "# Run SelectKBest\n",
        "X_new, selected_features = selectKBest_features(indep_X_encoded, dep_Y_encoded, 5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hi7-Ms1PVVPa",
        "outputId": "b751eedc-f7ec-482c-d391-5f9a67c88af5"
      },
      "id": "hi7-Ms1PVVPa",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸŽ¯ Top 5 selected features (SelectKBest):\n",
            "['duration', 'days_left', 'stops', 'source_city_Delhi', 'destination_city_Mumbai']\n",
            "\n",
            "Feature Scores:\n",
            "                    Feature     Score\n",
            "2                     stops  3.851276\n",
            "1                 days_left  3.223006\n",
            "0                  duration  1.523757\n",
            "22  destination_city_Mumbai  1.409482\n",
            "8         source_city_Delhi  1.319681\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Train-Test Split & Scaling\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_new, dep_Y_encoded, test_size=0.3, random_state=0)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n"
      ],
      "metadata": {
        "id": "YO2ApU83VYV7"
      },
      "id": "YO2ApU83VYV7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Train Classification Models\n",
        "\n",
        "# Logistic Regression\n",
        "log_clf = LogisticRegression(max_iter=500)\n",
        "log_clf.fit(X_train, y_train)\n",
        "y_pred_log = log_clf.predict(X_test)\n",
        "\n",
        "# Decision Tree\n",
        "dt_clf = DecisionTreeClassifier(random_state=0)\n",
        "dt_clf.fit(X_train, y_train)\n",
        "y_pred_dt = dt_clf.predict(X_test)\n",
        "\n",
        "# Random Forest\n",
        "rf_clf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
        "rf_clf.fit(X_train, y_train)\n",
        "y_pred_rf = rf_clf.predict(X_test)\n",
        "\n",
        "# Gradient Boosting\n",
        "gbr_clf = GradientBoostingClassifier(n_estimators=200, learning_rate=0.05, max_depth=3, random_state=0)\n",
        "gbr_clf.fit(X_train, y_train)\n",
        "y_pred_gbr = gbr_clf.predict(X_test)\n",
        "\n",
        "# XGBoost\n",
        "xgb_clf = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=1)\n",
        "xgb_clf.fit(X_train, y_train)\n",
        "y_pred_xgb = xgb_clf.predict(X_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNCFRUvNVdoD",
        "outputId": "93143ba2-9123-484b-c19f-7ba4a9682962"
      },
      "id": "dNCFRUvNVdoD",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [06:10:58] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 8: Evaluate Models\n",
        "def evaluate_model(y_test, y_pred, model_name):\n",
        "    print(f\"\\nðŸ“Š {model_name} Evaluation\")\n",
        "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "\n",
        "evaluate_model(y_test, y_pred_log, \"Logistic Regression\")\n",
        "evaluate_model(y_test, y_pred_dt, \"Decision Tree\")\n",
        "evaluate_model(y_test, y_pred_rf, \"Random Forest\")\n",
        "evaluate_model(y_test, y_pred_gbr, \"Gradient Boosting\")\n",
        "evaluate_model(y_test, y_pred_xgb, \"XGBoost\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wd2CM5v4Vf0c",
        "outputId": "b207dc4c-0b43-46e2-fe3b-42c560f39893"
      },
      "id": "wd2CM5v4Vf0c",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“Š Logistic Regression Evaluation\n",
            "Accuracy: 0.5666666666666667\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.86      0.65        14\n",
            "           1       0.71      0.31      0.43        16\n",
            "\n",
            "    accuracy                           0.57        30\n",
            "   macro avg       0.62      0.58      0.54        30\n",
            "weighted avg       0.62      0.57      0.53        30\n",
            "\n",
            "Confusion Matrix:\n",
            " [[12  2]\n",
            " [11  5]]\n",
            "\n",
            "ðŸ“Š Decision Tree Evaluation\n",
            "Accuracy: 0.6\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.64      0.60        14\n",
            "           1       0.64      0.56      0.60        16\n",
            "\n",
            "    accuracy                           0.60        30\n",
            "   macro avg       0.60      0.60      0.60        30\n",
            "weighted avg       0.61      0.60      0.60        30\n",
            "\n",
            "Confusion Matrix:\n",
            " [[9 5]\n",
            " [7 9]]\n",
            "\n",
            "ðŸ“Š Random Forest Evaluation\n",
            "Accuracy: 0.5666666666666667\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.79      0.63        14\n",
            "           1       0.67      0.38      0.48        16\n",
            "\n",
            "    accuracy                           0.57        30\n",
            "   macro avg       0.60      0.58      0.55        30\n",
            "weighted avg       0.60      0.57      0.55        30\n",
            "\n",
            "Confusion Matrix:\n",
            " [[11  3]\n",
            " [10  6]]\n",
            "\n",
            "ðŸ“Š Gradient Boosting Evaluation\n",
            "Accuracy: 0.36666666666666664\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.35      0.43      0.39        14\n",
            "           1       0.38      0.31      0.34        16\n",
            "\n",
            "    accuracy                           0.37        30\n",
            "   macro avg       0.37      0.37      0.37        30\n",
            "weighted avg       0.37      0.37      0.36        30\n",
            "\n",
            "Confusion Matrix:\n",
            " [[ 6  8]\n",
            " [11  5]]\n",
            "\n",
            "ðŸ“Š XGBoost Evaluation\n",
            "Accuracy: 0.5\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.79      0.59        14\n",
            "           1       0.57      0.25      0.35        16\n",
            "\n",
            "    accuracy                           0.50        30\n",
            "   macro avg       0.52      0.52      0.47        30\n",
            "weighted avg       0.53      0.50      0.46        30\n",
            "\n",
            "Confusion Matrix:\n",
            " [[11  3]\n",
            " [12  4]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 9: Save the best model (example: Random Forest)\n",
        "Finalised_Model = \"Finalized_classifier_selectkbest.sav\"\n",
        "pickle.dump(rf_clf, open(Finalised_Model, 'wb'))\n",
        "print(\"âœ… Classification model saved as Finalized_classifier_selectkbest.sav\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1OSEz3bViaB",
        "outputId": "59d9ca7d-5e8a-4ca8-8cc3-e70cc9630743"
      },
      "id": "X1OSEz3bViaB",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Classification model saved as Finalized_classifier_selectkbest.sav\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}